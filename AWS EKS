AWS EKS:
-------
Fundamentals
Networking ,
Storage,
Security,
LoadBalancers
Compute & Scaling
Upgrades & Maintenance
-------------------------
Fundamentals
-------------
1.what is EKS
--> EKS clster --kubernetes cluster --  control plane (etcd,api server,scheduler) -- Data Plane (worker nodes).
--> bridge between control plane and Data plane via ENI(Elastic Network Interface)
-->
An ENI (Elastic Network Interface) is a virtual network interface attached to an EC2 instance in a VPC. It includes:
>A primary private IP
>Optional secondary IPs
>One or more security groups
>A MAC address
>A source/destination check flag

In EKS (Elastic Kubernetes Service), ENIs play a critical role in networking for pods.

2.Kubernets clster in AWS with EC2
3.EKS as an integrator --common use cases
4.Architecture    EKS control node components(OIDC endpoint , AWS cloudwatch, Config map(authentication))
    -- Deployment options
	--AWS cloudFormation (Infrastructure as code)/ AWS CDK (cloud development kit)
	--Terraform  --EKS bleprints
	-- other services -pulumi --clster API
	-- AWS EKS cluster components (AWS EC2, VPCs, security groups , IAM roles, load balancers)
  --Tools needed for EKS (eksdemo -kubectl-like CLI for AWS EKS) (AWS IAM authenticator for k8) (Node groups , Scaling , VPC)
  --Kubernetes Networking --Flat Networking --3tier Architectre -ENI -Overlay Network
  --Authentication (OIDC,Auth configMap, EKS Auth)
 --------------------------------
 Networking 
 -------------------------------
  How CNI(container network interface) works?
 
 -------------------
 EKS EFS --storage
 EFS vs EBS
 CSI driver --Container Storage Interface driver
 Amazon S3 buckets , FSX , Local storage ,Amazon FSX for luster
 
 --------------
 EKS secrets:
 Config Map 
 Kubernetes secret
  Kubernetes secret Options
  Secret Storage 
  Options for Storing secrets -Hashicorp Vault , Secret Storage , AWS secret Store
  ---
  1.Secrets built into k8 are not encrypted. They are base 64-encoded 
  2. To protect secrets, put a stronger RBAC and namespace seperation and control these secrets inside as native secrets
  3.Using something external is a more secure way of managing secrets
  
  ğŸ” AWS EKS â€” Secrets Management (Deep Dive)
In Kubernetes (including EKS), managing secrets securely is crucial because you often deal with sensitive data:
Database passwords
API keys
Certificates

What is a Secret?
A Kubernetes Secret is an object used to store small amounts of sensitive data (like passwords, tokens, or keys).

-----------
Load Balancers in k8 --> applciation LB ... Network LB
Kube proxy
External DNS
Global LB
-------------
Summary:
-------
1.what a service is inside a k8 cluster
2.How services interacts  with the infrastrcture 
3.How services interacts with LB in general
4.How the AWS LB controller can create  and manage LoadBalancers that connect to services inside a k8 cluster 

-----------
Gateway Ingress
--------
Ingress inside k8
Managing Ingress with AWS LB
Ingress controllers
Services Mesh --Istio , Linkerd
AWS lattice --Handles gateway API

1. Gateway API and ingress controllers and how they work
2.Other options to get traffic in and out of the cluster
3.For those who dont want to use LB, Ingress is a great option

------------------
VPC Lattice 
----------
K8 Gateway API 
Traditional Approach with ingress controllers 
Gateway Classes and objects
Routing options with Gateway API
AWS Lattice for network Meshing
Service Networks in AWS lattice
-- Avoid lattice for small scale setups
-- Better for complex enterprise environments
-- challenges arise with scaling

AWS lattice --Challenges
--Heavy reliance on IAM permissions
--Dependency on AWS services for provisioning 
--service network creation time delay 

AWS lattice --Considerations
--Designed for advanced use cases 
-- Suitable for large scale environments
-- Requires seperation of concerns between teams
-- Integration across different environments and organisations
-- complexitiy hidden but not simple use

---------------
Compute & scaling :
----------------
ğŸ”· What is AWS Fargate?
AWS Fargate is a serverless compute engine for running containers without managing servers or EC2 instances.

ğŸ‘‰ You define container images + CPU/memory requirements â†’ AWS runs it.

âœ… No need to manage:
    EC2 Instances
    Auto Scaling Groups
    Patching or provisioning nodes

ğŸ”· Where Can You Use Fargate?
   Amazon ECS (Elastic Container Service)
   Amazon EKS (Elastic Kubernetes Service)
   
ğŸ”· EKS with Fargate
In EKS, you can deploy pods directly on Fargate, instead of EC2 nodes.

You get:
âœ… Fully managed nodes
âœ… Pay only per second of compute + memory
âœ… Automatic scaling
âœ… Native Kubernetes API (pods, services, etc.)


ğŸ”· Key Differences: EC2 vs Fargate in EKS
| Feature              | EC2 Worker Nodes   | Fargate (Serverless)                 |
| -------------------- | ------------------ | ------------------------------------ |
| Infrastructure Mgmt  | You manage EC2     | AWS manages compute                  |
| Scaling              | Manual or auto ASG | Auto per pod                         |
| Cost                 | Pay per EC2 hour   | Pay per pod second                   |
| Pod density tuning   | You tune per node  | AWS handles tuning                   |
| Kernel customization | Possible           | Not supported                        |
| Use cases            | Stateful, complex  | Stateless, microservices, batch jobs |


ğŸ”· Fargate Limitations (Important!)

Limited instance sizes (you can specify CPU + memory, but no full node control)
No support for:
  DaemonSets (no background system pods)
  Privileged containers
  Custom CNI plugins (must use AWS VPC CNI)
  GPU workloads
  StatefulSets with local persistent volumes

ğŸ”· Use Cases
âœ… Microservices / REST APIs
âœ… Event-driven / Batch jobs
âœ… Test environments
âœ… CI/CD pipeline workloads
âœ… Highly elastic workloads
âœ… "Throwaway" environments â€” no infra to manage

ğŸ”· Summary:
| Pros                                      | Cons                                    |
| ----------------------------------------- | --------------------------------------- |
| No infra to manage                        | No DaemonSets                           |
| Granular cost model                       | Less kernel customization               |
| Auto-scaling                              | Limited storage options                 |
| Secure isolation                          | Less control over underlying node types |
| Great for microservices & burst workloads | Not suited for all legacy workloads     |

ğŸš€ Final takeaway:
ğŸ‘‰ EKS + EC2 â†’ best for general purpose, mixed workloads
ğŸ‘‰ EKS + Fargate â†’ great for stateless, scalable, fast deployment

-----------------------------------------------------------------

EKS node groups:
--------------
Karpenter:  -> Autoscaling
-------------
ğŸ”· What is Karpenter?
ğŸ‘‰ Karpenter is an open-source, flexible, high-performance Kubernetes node autoscaler developed by AWS.
ğŸ‘‰ It can provision EC2 instances on-demand to handle changing cluster workloads.

ğŸ‘‰ It works with:
âœ… Amazon EKS
âœ… Any vanilla Kubernetes cluster on AWS

ğŸ”· How is Karpenter different from Cluster Autoscaler?
| Feature                | Cluster Autoscaler (CA) | Karpenter                                 |
| ---------------------- | ----------------------- | ----------------------------------------- |
| Scaling granularity    | Node group level        | Per pod / fine-grained                    |
| Launch time            | Slow                    | Fast (direct EC2 API)                     |
| Instance flexibility   | Static node groups      | Dynamic instance types, spot/ondemand mix |
| Pod topology awareness | No                      | Yes                                       |
| Custom instance shapes | No                      | Yes                                       |
| DaemonSet support      | Yes                     | Yes                                       |

ğŸ‘‰ In short â€” Karpenter is smarter, faster, more flexible than the older Cluster Autoscaler.

ğŸ”· Why Use Karpenter?
âœ… Handles bursty / spiky workloads
âœ… Provisions exact right instance types (cost-efficient)
âœ… Quickly scales down unused nodes
âœ… Automatically mixes:
   On-Demand instances
   Spot instances
âœ… Reduces cloud costs compared to over-provisioning with static EC2 node groups.

ğŸ”· How Does Karpenter Work?
Flow:
------
Kubernetes Scheduler
   â†“
Pending Pods detected
   â†“
Karpenter Controller sees pending pods
   â†“
Karpenter queries EC2 API â†’ Launches optimal instance
   â†“
EC2 instance joins cluster â†’ Pods scheduled


ğŸ‘‰ Karpenter directly calls EC2 APIs â€” no need to manage:
âœ… Node Groups
âœ… Launch Templates
âœ… ASGs

ğŸ”· Architecture
EKS Cluster
â”œâ”€â”€ Control Plane
â”œâ”€â”€ Karpenter Controller (in cluster)
â”œâ”€â”€ Karpenter Provisioners (YAML configs)
â””â”€â”€ EC2 API integration (via IAM role)


ğŸ”· Real Use Case Example
ğŸ‘‰ You run an EKS cluster that powers:
   API workloads with autoscaling
   Batch jobs with sudden CPU spikes
   Event-driven architecture (Kafka consumers)
ğŸ‘‰ Without Karpenter â†’ hard to tune EC2 Auto Scaling Groups.
ğŸ‘‰ With Karpenter â†’ cluster auto-adjusts capacity perfectly to the workload.

ğŸ”· Limitations / Considerations
âš ï¸ Currently works only on AWS (tightly integrated with EC2 API)
âš ï¸ Adds one more component to manage in your cluster
âš ï¸ Requires careful IAM setup for security

ğŸ”· Karpenter vs Cluster Autoscaler (Summary)
| When to use Karpenter       | When to use Cluster Autoscaler |
| --------------------------- | ------------------------------ |
| Dynamic workloads           | Stable workloads               |
| Flexible instance selection | Static node groups             |
| Cost optimization w/ Spot   | Managed node groups only       |
| Low latency scaling         | Basic scaling OK               |

ğŸ”· Final Takeaways
ğŸ‘‰ Karpenter = modern autoscaling layer for Kubernetes/EKS
ğŸ‘‰ Gives you cloud efficiency and cost savings
ğŸ‘‰ Replaces the need for rigid EC2 Auto Scaling Groups
ğŸ‘‰ Increasingly used in production Cloud Native architectures

ğŸš€ For Your Career (Cloud Engineer / Kubernetes Admin / Platform Engineer):
Mastering Karpenter is a strong plus:
âœ… Cost optimization
âœ… Autoscaling design
âœ… Spot instance utilization
âœ… Hybrid workloads handling

Next Options:
âœ… I can give you:
1ï¸âƒ£ Karpenter Hands-on Lab Guide (step by step EKS setup)
2ï¸âƒ£ Karpenter vs CA vs Fargate comparison sheet
3ï¸âƒ£ Karpenter Interview Q&A PDF
4ï¸âƒ£ Terraform template for deploying Karpenter with EKS
------------------------------

Redundancy and Resilence  --cluster access , IRSA -IAM role for service , Pod Identity , Security Grops for POD.
-------------------------
 
  ----------

Upgrades & maintenance 

---
EKS monitoing :
-------------
AWS Cloud watch (by default)
Cloud Watch log agents 
AWS Distro for open  Telemetry (ADOT)
AWS X-ray service 
Amazon managed Prometheus and Grafana 

--------
Upgrading EKS clusters --14months upgrading cycle
Upgrade Insights
Extended support 12 months .. in total 26months
EKS upgrades 
3releases evey year 
types -- In-place cluster upgrade , Ble-Green cluster upgrade 


---
Summary:
---
1. Node upgrades
2.How control plane gets upgraded 
3. Upgrading different types of compute in EKS cluster
4.Add-ons and calling the API
5. Cluster Insights and Kubent 
6. Blue-Green cluster upgrades 
------

EKS Add-ons
-------







